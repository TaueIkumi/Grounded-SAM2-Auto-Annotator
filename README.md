# Grounded SAM 2を用いたラベリング

**[Grounded-SAM-2](https://github.com/IDEA-Research/Grounded-SAM-2/tree/main)**

## 概要
本プロジェクトは、**Grounded-SAM-2 (GSAM2)** を用いて、LSMI Dataset（または任意の画像データ）に対してテキストプロンプトによる自動セグメンテーション（ラベリング）を行うツールです。

事前に定義されたクラス名（Pascal VOC 20クラスなど）をテキストプロンプトとして入力し、物体検出からセグメンテーションマスクの生成までを自動化しています。

## Grounded SAM 2 とは
Grounded SAM 2 は、以下の2つの強力なモデルをパイプラインとして組み合わせたシステムです。

1.  **Grounding DINO (Open-Set Object Detection)**
    * 任意のテキスト（"car", "person"など）を入力として受け取り、画像内の該当する物体を**バウンディングボックス（矩形）**で検出します。
2.  **SAM 2 (Segment Anything Model 2)**
    * Grounding DINOが出力したバウンディングボックスをプロンプト（ヒント）として受け取り、その内部の物体を**ピクセル単位のマスク**として高精度に切り抜きます。

これにより、「言葉で指示するだけ」で、対象物体の正確なセグメンテーションデータの作成が可能になります。

## 主な機能と特徴

* **テキスト駆動の自動ラベリング**: 任意のクラス名リスト（本実装ではPascal VOC）に基づいて検出を行います。
* **推論バッチサイズの制御**: GPUメモリの制約に合わせて、クラスリストを分割（Chunk）して推論する機能を実装しています（例: 1クラスずつ、5クラスずつ等）。
* **重複検出の除去 (NMS)**: 同一物体に対して複数のボックスが検出された場合、Non-Maximum Suppression (NMS) を適用して最適な1つのみを残します。
* **出力フォーマット**:
    * **可視化画像**: バウンディングボックス、ラベル、マスクを描画した画像。
    * **JSONデータ**: COCOフォーマットに準じたアノテーションデータ（BBox, RLE Mask, Score）。

## 環境構築
[INSTALL.md](#INSTALL.md)を参照

